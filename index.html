<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN">
<html>

<head>
  <title>Jack Turner</title>

  <meta charset="utf-8" />

  <meta name=viewport content="width=device-width, initial-scale=1">
  <link rel="icon" href="/resources/jt.png">
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
  <link href="https://fonts.googleapis.com/css?family=DM+Sans" rel="stylesheet">

  <style type="text/css">
    body {
      font-family: 'DM Sans', sans-serif !important;
    }


    a:link,
    a:hover,
    a:visited,
    a:active {
      color: #306BAC !important;
    }

    .nodecor:link,
    .nodecor:hover,
    .nodecor:visited,
    .nodecor:active {
      color: #333 !important;
      text-decoration: none;
    }

    .boldtext {
      font-weight: 700 !important;
    }

    .semiboldtext {
      font-weight: 500 !important;
    }

    .smalltext {
      font-size: .8em;
    }

    #name {
      font-size: 3.6em;
      line-height: 1em;
      margin-top: .5em;
      margin-bottom: .2em;
    }

    #title {
      font-size: 1.2em;
    }

    #email {
      font-family: Menlo, Monaco, Consolas, "Courier New", monospace;
      font-size: .9em;
      margin-top: 2px;
      margin-bottom: 2px;
    }

    #picpad {
      margin-top: .5em;
      margin-bottom: .5em;
    }

    #overview {
      font-size: 1.2em;
    }

    #projects {
      font-size: 1.1em;
    }

    #projects li {
      margin-top: .5em;
    }

    @media only screen and (max-width: 750px) {
      #fadeshow1 {
        display: none;
      }
    }

    .content {
      margin: auto;
      max-width: 800px;
      padding: 10px;
    }

    .subcontent {
      margin-top: 1em;
      margin-bottom: 1.5em;
    }

    .pubtitle {
      font-weight: 500;
    }


    .pubyear {
      margin-top: 12px;
      clear: both;
      font-size: 1.2em;
      color: 222;
    }

    .pubaward {
      font-weight: 600;
      font-style: italic;
    }

    /* Add a card effect for articles */
    .card {
      background-color: white;
      padding: 20px;
      margin-top: 20px;
    }

    .authlist {
      font-size: 12px;
      color: gray;
    }

    .title {
      font-size: 18px;
      font-weight: bold;
    }

    .date {
      font-size: 12px;
    }

    .abstract {
      font-size: 14px;
    }
  </style>
</head>

<body>

  <div class="content" style="margin-top: 5.5rem;">

    <div class="row">
      <div class="col-sm-offset-5 col-sm-8">
        <div id="name">
          <div class="semiboldtext">Jack Turner</div>
        </div>
        <div id="title" style="margin-top: 1.5rem;">
          <div>PhD student, University of Edinburgh</div>
          <div id="email">jack.turner@ed.ac.uk</div>

          <div style="margin-top: 1.5rem;"></div>
          <div style="font-size: 1em;"><a href="resources/Resume.pdf">cv</a> · <a
              href="https://github.com/jack-willturner">github</a> · <a
              href="https://scholar.google.co.uk/citations?user=FPGHMRgAAAAJ&hl=en">scholar</a></div>

        </div>
      </div>

      <div class="col-sm-4">
        <img class="float-right" src="resources/profile.jpeg" id="fadeshow1" alt="pdb" id="pdb-pic"
          style="height: 220px; margin-top: 10px;">
      </div>

    </div>

    <div class="col-sm-offset-2">
      <div id="overview" style="margin-top: 1.5rem;">

        <hr>
        <p>
          I am a third year PhD student at the University of Edinburgh, supervised by <a
            href="http://www.dcs.ed.ac.uk/home/mob/">Professor Michael O’Boyle</a> and <a
            href="https://elliotjcrowley.github.io">Lecturer (Asst. Prof.) Elliot J. Crowley</a>. I'm in the fourth year
          of the <a href="http://web.inf.ed.ac.uk/infweb/student-services/cdt/pervasive-parallelism">Pervasive
            Parallelism</a>
          CDT programme.
        </p>

        <p>
          My research interests include (but are not limited to!):
        <ul>
          <li> Architecture rewriting in neural networks
          <li> Optimising compilers
          <li> Program transformations
        </ul>
        </p>

        <p>
          In my spare time I enjoy baking bread, climbing rocks, and using Oxford commas.
        </p>
      </div>
    </div>

    <div class="col-sm-offset-2">

      <div style="margin-top: 3.5rem;"></div>
      <div>
        <h3>Conference papers</h4>
          <div id="publist">

            <div id="publist">
              <div class="container card">
                <div class="row">
                  <div class="col-sm-2 date">
                    18th July, 2021
                    <span class="badge badge-primary" style="font-size:8px;">ICML</span>
                    <img src="resources/long-talk.png" style="width:75px; margin-top: 10px;">
                  </div>
                  <div class="col-sm-7">
                    <a class="pubtitle" href="https://arxiv.org/abs/2006.04647">
                      <p class="title"> Neural Architecture Search Without Training </p>
                    </a>
                    <p class="authlist">Joseph Mellor, Jack Turner, Amos Storkey, Elliot J. Crowley.</p>
                    <p class="abstract">
                      A low-cost measure for scoring networks at initialisation
                      which allows us to perform architecture search in a matter
                      of seconds instead of hours or days.
                    </p>
                  </div>
                  <div class="col-sm-1.5">
                    <img src="resources/naswot.png" id="fadeshow1" style="width:150px;">
                  </div>
                </div>
              </div>
            </div>

            <div id="pubtitle">
              <div class="container card">
                <div class="row">
                  <div class="col-sm-2 date">
                    19th Apr, 2021
                    <span class="badge badge-primary" style="font-size:8px;">ASPLOS</span>
                    <img src="resources/dist-paper.png" style="width:75px; margin-top: 10px;">
                    <img>
                  </div>
                  <div class="col-sm-7">
                    <a class="pubtitle" href="https://arxiv.org/abs/2102.06599">
                      <p class="title">Neural Architecture Search as Program Transformation Exploration </p>
                    </a>
                    <p class="authlist">Jack Turner, Elliot J. Crowley, Michael O'Boyle.</p>
                    <p class="abstract">
                      A compiler-oriented approach to neural architecture search
                      which allows us to generate new types of convolution.
                    </p>
                  </div>
                  <div class="col-sm-1.5">
                    <img src="resources/poly.png" id="fadeshow1" style="width:150px;">
                  </div>
                </div>
              </div>
            </div>


            <div id="pubtitle">
              <div class="container card">
                <div class="row">
                  <div class="col-sm-2 date">
                    6th Dec, 2020
                    <span class="badge badge-primary" style="font-size:8px;">NeurIPS</span>
                    <img src="resources/spotlight.png" style="width:75px; margin-top: 10px;">
                  </div>
                  <div class="col-sm-7">
                    <a class="pubtitle" href="https://arxiv.org/abs/1910.05199">
                      <p class="title"> Bayesian Meta-Learning for the Few-Shot Setting via Deep Kernels </p>
                    </a>
                    <p class="authlist">Massimiliano Patacchiola, Jack Turner, Elliot J. Crowley, Michael O'Boyle, Amos
                      Storkey.</p>
                    <p class="abstract">
                      A Bayesian treatment for the meta-learning inner loop through the use of Gaussian Processes
                      and neural networks.
                    </p>
                  </div>
                  <div class="col-sm-1.5">
                    <img src="resources/gp.png" id="fadeshow1" style="width:150px;">
                  </div>
                </div>
              </div>
            </div>


            <div id="pubtitle">
              <div class="container card">
                <div class="row">
                  <div class="col-sm-2 date">
                    26th Apr, 2020
                    <span class="badge badge-primary" style="font-size:8px;">ICLR</span>
                  </div>
                  <div class="col-sm-7">
                    <a class="pubtitle" href="https://arxiv.org/abs/1906.04113">
                      <p class="title"> BlockSwap: Fisher-guided Block Substitution for Network Compression </p>
                    </a>
                    <p class="authlist">Jack Turner, Elliot J. Crowley, Amos Storkey, Michael O'Boyle, Gavin Gray.</p>
                    <p class="abstract">
                      One-shot compression of neural networks by swapping out residual
                      blocks for cheaper alternatives, guided by Fisher Information at
                      initialisation.
                    </p>
                  </div>
                  <div class="col-sm-1.5" id="fadeshow1">
                    <img src="resources/blockswap.png" style="width:150px;">
                  </div>
                </div>
              </div>
            </div>


            <div id="pubtitle">
              <div class="container card">
                <div class="row">
                  <div class="col-sm-2 date">
                    30th Feb, 2018
                    <span class="badge badge-primary" style="font-size:8px;">IISWC</span>
                  </div>
                  <div class="col-sm-7">
                    <a class="pubtitle" href="https://arxiv.org/abs/1809.07196">
                      <p class="title"> Characterising Across-Stack Optimisations for Deep Neural Networks </p>
                    </a>
                    <p class="authlist">Jack Turner, José Cano, Valentin Radu, Elliot J. Crowley, Amos Storkey, Michael
                      O'Boyle.</p>
                    <p class="abstract">
                      A study on the interaction of optimisations applied at different levels
                      of the compilation stack for neural networks - from neural architectural
                      decisions through to hardware design.
                    </p>
                  </div>
                  <div class="col-sm-1.5">
                    <img src="resources/charac.png" id="fadeshow1" style="width:150px;">
                  </div>
                </div>
              </div>
            </div>

          </div>
      </div>
    </div>


    <div class="col-sm-offset-2">
      <div style="margin-top: 3.5rem;"></div>
      <div>
        <h3>Workshops/Preprints</h4>

          <div id="publist">
            <div class="container card">
              <div class="row">
                <div class="col-sm-2 date">
                  7th June, 2019
                  <span class="badge badge-info" style="font-size:8px;">NeurIPS</span>
                  <span class="badge badge-info" style="font-size:8px;">CDNNRIA</span>
                </div>
                <div class="col-sm-7">
                  <a class="pubtitle" href="https://arxiv.org/abs/1810.04622">
                    <p class="title"> Pruning neural networks: is it time to nip it in the bud? </p>
                  </a>
                  <p class="authlist">Elliot J. Crowley, Jack Turner, Michael O'Boyle, Amos Storkey.</p>
                  <p class="abstract">
                    An investigation into the efficacy of structured pruning
                    for compressing neural networks. We show that simple
                    downscaling schemes can be used to produce more performant
                    networks than their pruned equivalents.
                  </p>
                </div>
                <div class="col-sm-1.5">
                  <img src="resources/spruning.png" id="fadeshow1" style="width:150px;">
                </div>
              </div>
            </div>
          </div>



      </div>
    </div>


    <div class="col-sm-offset-2">
      <div style="margin-top: 3.5rem;"></div>
      <div>
        <h3>Blog Posts</h4>
          <div id="publist">
            <ul>
              <li><a class="pubtitle" href="https://jack-willturner.github.io/posts/vision-transformer.html"> Vision
                  Transformer</a>. <span class="pubmetadata"><span class="pubauthors">A verbose implementation of the
                    forward pass of the vision transformer model, broken down step-by-step.</span> <span
                    class="pubvenue"></span></span></span></li>
              <li><a class="pubtitle" href="https://jack-willturner.github.io/posts/lin_regression.html"> Linear
                  Regression Both Ways</a>. <span class="pubmetadata"><span class="pubauthors">A quick explanation of
                    fitting linear regression with both gradient descent and the normal equations. Assumes some comfort
                    with linear algebra.</span> <span class="pubvenue"></span></span></span></li>
              <li><a class="pubtitle" href="https://jack-willturner.github.io/posts/call-by-obj.html"> Call by Object
                  Reference</a>. <span class="pubmetadata"><span class="pubauthors">A note on Python's
                    call-by-object-reference system for those who want a brief overview or have been caught out by it
                    before.</span> <span class="pubvenue"></span></span></span></li>
              <li><a class="pubtitle" href="https://jack-willturner.github.io/posts/gps.html"> Exact Gaussian Processes
                  in NumPy</a>. <span class="pubmetadata"><span class="pubauthors">Some introductory notes on Gaussian
                    Processes and a small, self-contained implementation in NumPy.</span> <span
                    class="pubvenue"></span></span></span></li>
              <li><a class="pubtitle" href="https://jack-willturner.github.io/posts/systems-for-ml.html"> Computer
                  Science Introductions</a>. <span class="pubmetadata"><span class="pubauthors">My favourite resources
                    for learning about Computer Science, especially aimed at Machine Learners who come from non-CS
                    backgrounds.</span> <span class="pubvenue"></span></span></span></li>
            </ul>
          </div>
      </div>
    </div>

  </div>
</body>

</html>